{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34259ba-80ac-4f68-ae9a-9423ecac80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '20'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c98183-e171-4c9c-a1e0-abf94eb2cac1",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe5df79-ac77-41ec-8a5e-2ad41c01f9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>No Game No Life: Zero (2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>Flint (2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title\n",
       "index                                           \n",
       "0                               Toy Story (1995)\n",
       "1                                 Jumanji (1995)\n",
       "2                        Grumpier Old Men (1995)\n",
       "3                       Waiting to Exhale (1995)\n",
       "4             Father of the Bride Part II (1995)\n",
       "...                                          ...\n",
       "9737   Black Butler: Book of the Atlantic (2017)\n",
       "9738                No Game No Life: Zero (2017)\n",
       "9739                                Flint (2017)\n",
       "9740         Bungo Stray Dogs: Dead Apple (2018)\n",
       "9741         Andrew Dice Clay: Dice Rules (1991)\n",
       "\n",
       "[9742 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv('./temp/ml-latest-small/movies.csv')\n",
    "# In collaborative filtering method, we imagine there is no information about the movies like their categories\n",
    "movies_df = movies_df.drop('genres', axis=1) \n",
    "movies_df.index.name = 'index'\n",
    "# helper dictionaries to help memory usage for embeddings\n",
    "index_to_movieId = dict(movies_df.movieId)\n",
    "movieId_to_index = {v:k for k, v in index_to_movieId.items()}\n",
    "movies_df = movies_df.drop('movieId', axis=1)\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32212f2e-f697-4a6c-935d-420e49cfbe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9434</th>\n",
       "      <td>610</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9461</th>\n",
       "      <td>610</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>610</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>610</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9503</th>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  rating\n",
       "index                \n",
       "0           1     4.0\n",
       "2           1     4.0\n",
       "5           1     4.0\n",
       "43          1     5.0\n",
       "46          1     5.0\n",
       "...       ...     ...\n",
       "9434      610     4.0\n",
       "9461      610     5.0\n",
       "9462      610     5.0\n",
       "9463      610     5.0\n",
       "9503      610     3.0\n",
       "\n",
       "[100836 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.read_csv('./temp/ml-latest-small/ratings.csv')\n",
    "users_df = users_df.drop('timestamp', axis=1)\n",
    "users_df['index'] = users_df['movieId'].map(lambda x: movieId_to_index[x])\n",
    "\n",
    "# Take the average rating for mean normalization\n",
    "average_rating = users_df.drop('userId', axis=1).groupby('movieId').mean()\n",
    "\n",
    "users_df = users_df.set_index('index')\n",
    "users_df = users_df.drop('movieId', axis=1)\n",
    "\n",
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8808885-9297-436c-aad5-52d587013230",
   "metadata": {},
   "source": [
    "### Create Movie/User rating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62b37a5-d629-44b5-a7e8-518c116ea237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9724 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId  1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
       "index                                                     ...                  \n",
       "0       4.0  0.0  0.0  0.0  4.0  0.0  4.5  0.0  0.0  0.0  ...  4.0  0.0  4.0   \n",
       "1       0.0  0.0  0.0  0.0  0.0  4.0  0.0  4.0  0.0  0.0  ...  0.0  4.0  0.0   \n",
       "2       4.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3       0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4       0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9737    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9738    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9739    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9740    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "9741    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "userId  604  605  606  607  608  609  610  \n",
       "index                                      \n",
       "0       3.0  4.0  2.5  4.0  2.5  3.0  5.0  \n",
       "1       5.0  3.5  0.0  0.0  2.0  0.0  0.0  \n",
       "2       0.0  0.0  0.0  0.0  2.0  0.0  0.0  \n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       3.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "9737    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9738    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9739    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9740    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9741    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[9724 rows x 610 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rating_df = users_df.join(movies_df, on='index')\n",
    "# save the titles mapping, movieId to title, for evaluation\n",
    "titles = movie_rating_df['title']\n",
    "movie_rating_df = movie_rating_df.drop('title', axis=1)\n",
    "movie_rating_df.pivot_table(values='rating', index='index', columns='userId').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb1f26-ea5f-46b4-8a23-776c767d216d",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a977fa7d-3d44-425a-80e4-7f492609a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training movies has the shape (80668,)\n",
      "Training users has the shape (80668,)\n",
      "Training ratings has the shape (80668,)\n",
      "\n",
      "Test movies has the shape (20168,)\n",
      "Test users has the shape (20168,)\n",
      "Test ratings has the shape (20168,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "movies = movie_rating_df.index.values\n",
    "users = movie_rating_df['userId'].values\n",
    "Y = movie_rating_df['rating'].values.astype('float32')\n",
    "\n",
    "\n",
    "# mean normalize the labels\n",
    "mu = np.mean(Y, axis=0)\n",
    "Y = Y - mu\n",
    "\n",
    "\n",
    "# split the data into training set and validation set\n",
    "training_movies, test_movies, training_users, test_users, training_ratings, test_ratings = train_test_split(movies,\n",
    "                                                                                                            users, \n",
    "                                                                                                            Y,\n",
    "                                                                                                            test_size=0.2, shuffle=True)\n",
    "print(f'Training movies has the shape', training_movies.shape)\n",
    "print(f'Training users has the shape', training_users.shape)\n",
    "print(f'Training ratings has the shape', training_ratings.shape)\n",
    "print()\n",
    "print(f'Test movies has the shape', test_movies.shape)\n",
    "print(f'Test users has the shape', test_users.shape)\n",
    "print(f'Test ratings has the shape', test_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978deb29-dd85-46ba-90e3-c00d8a8c89b3",
   "metadata": {},
   "source": [
    "### Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "316ce688-3071-4ec8-a558-13ad67a65c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER = 1000\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((training_movies, training_users, training_ratings))\n",
    "train_ds = train_ds.shuffle(BUFFER)\n",
    "train_ds = train_ds.batch(BATCH_SIZE, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_movies, test_users, test_ratings))\n",
    "test_ds = test_ds.batch(BATCH_SIZE, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7199a373-e1c8-4107-a8bc-9a8fdcda1d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4245 4229 2526 ... 5995 3770 6626], shape=(1024,), dtype=int64)\n",
      "tf.Tensor([428 567  59 ... 380 419 380], shape=(1024,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 0.49844313 -3.0015569   0.49844313 ... -0.5015569   0.9984431\n",
      "  0.49844313], shape=(1024,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for movie, user, rate in train_ds.take(1):\n",
    "    print(movie)\n",
    "    print(user)\n",
    "    print(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d4bde-e343-434a-abcc-1a90c2e4e080",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00b02f8a-7ad9-4465-975b-f9ee12d59fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Input, Dot, Embedding, Layer\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import MeanAbsoluteError, Metric\n",
    "from keras.models import Model\n",
    "from keras.regularizers import L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a633433-27fa-4e37-842b-1ee6cc74b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(Model):\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 num_movies, \n",
    "                 num_users, \n",
    "                 user_embedding_dim, \n",
    "                 movie_embbeding_dim):\n",
    "        \n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        self.user_embedding = Embedding(input_dim=num_users, \n",
    "                                        output_dim=user_embedding_dim, \n",
    "                                        name='user_embed')\n",
    "        self.movie_embedding = Embedding(input_dim=num_movies, \n",
    "                                         output_dim=movie_embbeding_dim, \n",
    "                                         name='movie_embed')\n",
    "        self.dot = Dot(axes=1, normalize=True, name='dot')\n",
    "\n",
    "        self.build()\n",
    "\n",
    "    \n",
    "    def build(self):\n",
    "        user = Input(shape=())\n",
    "        movie = Input(shape=())\n",
    "        self.call(movie, user)\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, movie, user, training=False):\n",
    "        user = self.user_embedding(user)\n",
    "        movie = self.movie_embedding(movie)\n",
    "        return self.dot([user, movie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32f9aa61-d694-49be-b0cb-2b96ffb05e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"collaborative_filtering_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_34 (Embedding)    (None, 64)                39104     \n",
      "                                                                 \n",
      " embedding_35 (Embedding)    (None, 64)                622400    \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dot_17 (Dot)                (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 661504 (2.52 MB)\n",
      "Trainable params: 661504 (2.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CollaborativeFiltering(units=128,\n",
    "                               num_movies=np.unique(movies).shape[0] + 1, \n",
    "                               num_users=np.unique(users).shape[0] + 1, \n",
    "                               user_embedding_dim=64, \n",
    "                               movie_embbeding_dim=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "47f740b3-8045-4c55-944b-df4a7ebb8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4ea3d3bc-041f-44ff-8cd7-91e092c465a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(initial_learning_rate=1e-3, min_learning_rate=1e-5, weight=0.9):\n",
    "    def func(epoch):\n",
    "        return max(initial_learning_rate * weight ** (epoch), min_learning_rate)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9d5159c3-51d6-4310-9659-95902c0ecd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae = MeanAbsoluteError(name='train_mae')\n",
    "validation_mae = MeanAbsoluteError(name='test_mae')\n",
    "optimizer = Adam()\n",
    "scheduler = get_scheduler(initial_learning_rate=3e-3, weight=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08300e3-8104-4aac-b910-7027d3cbb492",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b292e36e-3af4-4f65-ae9a-96fb04e9ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(movie, user, y_true):\n",
    "    loss = 0.0\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(movie, user, training=True)\n",
    "        loss = loss_func(y_true, y_pred)\n",
    "        train_mae.update_state(y_true, y_pred)\n",
    "        \n",
    "    variables = model.trainable_variables\n",
    "    grads = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(grads, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d69fbbbb-e9d1-4eac-9e3d-39e58d76efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def validation_step(movie, user, y_true):\n",
    "    y_pred = model(movie, user, training=False)\n",
    "    loss = loss_func(y_true, y_pred)\n",
    "    validation_mae.update_state(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "da66c7bd-c7ea-41f5-96bc-d2d9f58c555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1\n",
      "  6 sec | Step  78\tLoss: 1.0757\t MAE: 0.8278\n",
      "  6 sec | Step  19\tLoss: 1.0077\t MAE: 0.7944\n",
      "Epoch   2\n",
      "  1 sec | Step  78\tLoss: 0.7192\t MAE: 0.6494\n",
      "  1 sec | Step  19\tLoss: 0.8895\t MAE: 0.7319\n",
      "Epoch   3\n",
      "  0 sec | Step  78\tLoss: 0.6132\t MAE: 0.5906\n",
      "  0 sec | Step  19\tLoss: 0.8506\t MAE: 0.7123\n",
      "Epoch   4\n",
      "  0 sec | Step  78\tLoss: 0.5756\t MAE: 0.5691\n",
      "  0 sec | Step  19\tLoss: 0.8339\t MAE: 0.7044\n",
      "Epoch   5\n",
      "  0 sec | Step  78\tLoss: 0.5581\t MAE: 0.5589\n",
      "  0 sec | Step  19\tLoss: 0.8253\t MAE: 0.7005\n",
      "Epoch   6\n",
      "  0 sec | Step  78\tLoss: 0.5482\t MAE: 0.5531\n",
      "  0 sec | Step  19\tLoss: 0.8201\t MAE: 0.6981\n",
      "Epoch   7\n",
      "  0 sec | Step  78\tLoss: 0.5415\t MAE: 0.5491\n",
      "  0 sec | Step  19\tLoss: 0.8167\t MAE: 0.6967\n",
      "Epoch   8\n",
      "  0 sec | Step  78\tLoss: 0.5367\t MAE: 0.5461\n",
      "  0 sec | Step  19\tLoss: 0.8144\t MAE: 0.6956\n",
      "Epoch   9\n",
      "  0 sec | Step  78\tLoss: 0.5331\t MAE: 0.5439\n",
      "  0 sec | Step  19\tLoss: 0.8127\t MAE: 0.6949\n",
      "Epoch  10\n",
      "  0 sec | Step  78\tLoss: 0.5300\t MAE: 0.5419\n",
      "  0 sec | Step  19\tLoss: 0.8115\t MAE: 0.6944\n",
      "Epoch  11\n",
      "  0 sec | Step  78\tLoss: 0.5276\t MAE: 0.5403\n",
      "  0 sec | Step  19\tLoss: 0.8105\t MAE: 0.6940\n",
      "Epoch  12\n",
      "  0 sec | Step  78\tLoss: 0.5254\t MAE: 0.5388\n",
      "  0 sec | Step  19\tLoss: 0.8098\t MAE: 0.6937\n",
      "Epoch  13\n",
      "  0 sec | Step  78\tLoss: 0.5235\t MAE: 0.5376\n",
      "  0 sec | Step  19\tLoss: 0.8092\t MAE: 0.6934\n",
      "Epoch  14\n",
      "  0 sec | Step  78\tLoss: 0.5219\t MAE: 0.5365\n",
      "  0 sec | Step  19\tLoss: 0.8087\t MAE: 0.6932\n",
      "Epoch  15\n",
      "  0 sec | Step  78\tLoss: 0.5203\t MAE: 0.5355\n",
      "  0 sec | Step  19\tLoss: 0.8084\t MAE: 0.6930\n",
      "Epoch  16\n",
      "  0 sec | Step  78\tLoss: 0.5190\t MAE: 0.5346\n",
      "  0 sec | Step  19\tLoss: 0.8079\t MAE: 0.6928\n",
      "Epoch  17\n",
      "  0 sec | Step  78\tLoss: 0.5178\t MAE: 0.5337\n",
      "  0 sec | Step  19\tLoss: 0.8077\t MAE: 0.6927\n",
      "Epoch  18\n",
      "  0 sec | Step  78\tLoss: 0.5167\t MAE: 0.5330\n",
      "  0 sec | Step  19\tLoss: 0.8074\t MAE: 0.6926\n",
      "Epoch  19\n",
      "  0 sec | Step  78\tLoss: 0.5157\t MAE: 0.5323\n",
      "  0 sec | Step  19\tLoss: 0.8073\t MAE: 0.6925\n",
      "Epoch  20\n",
      "  0 sec | Step  78\tLoss: 0.5147\t MAE: 0.5316\n",
      "  0 sec | Step  19\tLoss: 0.8071\t MAE: 0.6925\n",
      "Epoch  21\n",
      "  0 sec | Step  78\tLoss: 0.5138\t MAE: 0.5310\n",
      "  0 sec | Step  19\tLoss: 0.8070\t MAE: 0.6924\n",
      "Epoch  22\n",
      "  0 sec | Step  78\tLoss: 0.5131\t MAE: 0.5305\n",
      "  0 sec | Step  19\tLoss: 0.8069\t MAE: 0.6924\n",
      "Epoch  23\n",
      "  0 sec | Step  78\tLoss: 0.5123\t MAE: 0.5299\n",
      "  0 sec | Step  19\tLoss: 0.8067\t MAE: 0.6923\n",
      "Epoch  24\n",
      "  0 sec | Step  78\tLoss: 0.5117\t MAE: 0.5295\n",
      "  0 sec | Step  19\tLoss: 0.8066\t MAE: 0.6922\n",
      "Epoch  25\n",
      "  0 sec | Step  78\tLoss: 0.5110\t MAE: 0.5291\n",
      "  0 sec | Step  19\tLoss: 0.8066\t MAE: 0.6922\n",
      "Epoch  26\n",
      "  0 sec | Step  78\tLoss: 0.5103\t MAE: 0.5286\n",
      "  0 sec | Step  19\tLoss: 0.8065\t MAE: 0.6922\n",
      "Epoch  27\n",
      "  0 sec | Step  78\tLoss: 0.5098\t MAE: 0.5282\n",
      "  0 sec | Step  19\tLoss: 0.8064\t MAE: 0.6922\n",
      "Epoch  28\n",
      "  0 sec | Step  78\tLoss: 0.5093\t MAE: 0.5279\n",
      "  0 sec | Step  19\tLoss: 0.8064\t MAE: 0.6921\n",
      "Epoch  29\n",
      "  0 sec | Step  78\tLoss: 0.5086\t MAE: 0.5274\n",
      "  0 sec | Step  19\tLoss: 0.8063\t MAE: 0.6921\n",
      "Epoch  30\n",
      "  0 sec | Step  78\tLoss: 0.5081\t MAE: 0.5271\n",
      "  0 sec | Step  19\tLoss: 0.8063\t MAE: 0.6921\n",
      "Epoch  31\n",
      "  0 sec | Step  78\tLoss: 0.5076\t MAE: 0.5268\n",
      "  0 sec | Step  19\tLoss: 0.8063\t MAE: 0.6921\n",
      "Epoch  32\n",
      "  0 sec | Step  78\tLoss: 0.5072\t MAE: 0.5265\n",
      "  0 sec | Step  19\tLoss: 0.8062\t MAE: 0.6921\n",
      "Epoch  33\n",
      "  0 sec | Step  78\tLoss: 0.5068\t MAE: 0.5262\n",
      "  0 sec | Step  19\tLoss: 0.8062\t MAE: 0.6920\n",
      "Epoch  34\n",
      "  0 sec | Step  78\tLoss: 0.5065\t MAE: 0.5259\n",
      "  0 sec | Step  19\tLoss: 0.8062\t MAE: 0.6920\n",
      "Epoch  35\n",
      "  0 sec | Step  78\tLoss: 0.5060\t MAE: 0.5256\n",
      "  0 sec | Step  19\tLoss: 0.8061\t MAE: 0.6920\n",
      "Epoch  36\n",
      "  0 sec | Step  78\tLoss: 0.5057\t MAE: 0.5254\n",
      "  0 sec | Step  19\tLoss: 0.8061\t MAE: 0.6920\n",
      "Epoch  37\n",
      "  0 sec | Step  78\tLoss: 0.5053\t MAE: 0.5252\n",
      "  0 sec | Step  19\tLoss: 0.8061\t MAE: 0.6920\n",
      "Epoch  38\n",
      "  0 sec | Step  78\tLoss: 0.5049\t MAE: 0.5249\n",
      "  0 sec | Step  19\tLoss: 0.8061\t MAE: 0.6920\n",
      "Epoch  39\n",
      "  0 sec | Step  78\tLoss: 0.5046\t MAE: 0.5247\n",
      "  0 sec | Step  19\tLoss: 0.8061\t MAE: 0.6920\n",
      "Epoch  40\n",
      "  0 sec | Step  78\tLoss: 0.5044\t MAE: 0.5245\n",
      "  0 sec | Step  19\tLoss: 0.8061\t MAE: 0.6920\n",
      "Epoch  41\n",
      "  0 sec | Step  78\tLoss: 0.5040\t MAE: 0.5243\n",
      "  0 sec | Step  19\tLoss: 0.8061\t MAE: 0.6920\n",
      "Epoch  42\n",
      "  0 sec | Step  78\tLoss: 0.5038\t MAE: 0.5241\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  43\n",
      "  0 sec | Step  78\tLoss: 0.5036\t MAE: 0.5240\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  44\n",
      "  0 sec | Step  78\tLoss: 0.5033\t MAE: 0.5238\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  45\n",
      "  0 sec | Step  78\tLoss: 0.5031\t MAE: 0.5237\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  46\n",
      "  0 sec | Step  78\tLoss: 0.5027\t MAE: 0.5235\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  47\n",
      "  0 sec | Step  78\tLoss: 0.5027\t MAE: 0.5234\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  48\n",
      "  0 sec | Step  78\tLoss: 0.5024\t MAE: 0.5233\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  49\n",
      "  0 sec | Step  78\tLoss: 0.5023\t MAE: 0.5232\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  50\n",
      "  0 sec | Step  78\tLoss: 0.5021\t MAE: 0.5231\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  51\n",
      "  0 sec | Step  78\tLoss: 0.5018\t MAE: 0.5228\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  52\n",
      "  0 sec | Step  78\tLoss: 0.5016\t MAE: 0.5227\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  53\n",
      "  0 sec | Step  78\tLoss: 0.5016\t MAE: 0.5227\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  54\n",
      "  0 sec | Step  78\tLoss: 0.5014\t MAE: 0.5225\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  55\n",
      "  0 sec | Step  78\tLoss: 0.5013\t MAE: 0.5225\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  56\n",
      "  0 sec | Step  78\tLoss: 0.5012\t MAE: 0.5224\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  57\n",
      "  0 sec | Step  78\tLoss: 0.5011\t MAE: 0.5223\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  58\n",
      "  0 sec | Step  78\tLoss: 0.5009\t MAE: 0.5222\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  59\n",
      "  0 sec | Step  78\tLoss: 0.5007\t MAE: 0.5221\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  60\n",
      "  0 sec | Step  78\tLoss: 0.5006\t MAE: 0.5220\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  61\n",
      "  0 sec | Step  78\tLoss: 0.5005\t MAE: 0.5219\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  62\n",
      "  0 sec | Step  78\tLoss: 0.5005\t MAE: 0.5219\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  63\n",
      "  0 sec | Step  78\tLoss: 0.5003\t MAE: 0.5218\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  64\n",
      "  0 sec | Step  78\tLoss: 0.5002\t MAE: 0.5217\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  65\n",
      "  0 sec | Step  78\tLoss: 0.5001\t MAE: 0.5216\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  66\n",
      "  0 sec | Step  78\tLoss: 0.5000\t MAE: 0.5216\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  67\n",
      "  0 sec | Step  78\tLoss: 0.4999\t MAE: 0.5215\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  68\n",
      "  0 sec | Step  78\tLoss: 0.5000\t MAE: 0.5216\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  69\n",
      "  0 sec | Step  78\tLoss: 0.4998\t MAE: 0.5214\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  70\n",
      "  0 sec | Step  78\tLoss: 0.4998\t MAE: 0.5214\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  71\n",
      "  0 sec | Step  78\tLoss: 0.4997\t MAE: 0.5213\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  72\n",
      "  0 sec | Step  78\tLoss: 0.4997\t MAE: 0.5214\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  73\n",
      "  0 sec | Step  78\tLoss: 0.4997\t MAE: 0.5214\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  74\n",
      "  0 sec | Step  78\tLoss: 0.4995\t MAE: 0.5212\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  75\n",
      "  0 sec | Step  78\tLoss: 0.4994\t MAE: 0.5212\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  76\n",
      "  0 sec | Step  78\tLoss: 0.4993\t MAE: 0.5211\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  77\n",
      "  0 sec | Step  78\tLoss: 0.4993\t MAE: 0.5211\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  78\n",
      "  0 sec | Step  78\tLoss: 0.4992\t MAE: 0.5211\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  79\n",
      "  0 sec | Step  78\tLoss: 0.4993\t MAE: 0.5211\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  80\n",
      "  0 sec | Step  78\tLoss: 0.4993\t MAE: 0.5211\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  81\n",
      "  0 sec | Step  78\tLoss: 0.4993\t MAE: 0.5211\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  82\n",
      "  0 sec | Step  78\tLoss: 0.4992\t MAE: 0.5210\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  83\n",
      "  0 sec | Step  78\tLoss: 0.4992\t MAE: 0.5210\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  84\n",
      "  0 sec | Step  78\tLoss: 0.4991\t MAE: 0.5210\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  85\n",
      "  0 sec | Step  78\tLoss: 0.4991\t MAE: 0.5210\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  86\n",
      "  0 sec | Step  78\tLoss: 0.4990\t MAE: 0.5209\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  87\n",
      "  0 sec | Step  78\tLoss: 0.4990\t MAE: 0.5209\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  88\n",
      "  0 sec | Step  78\tLoss: 0.4990\t MAE: 0.5209\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  89\n",
      "  0 sec | Step  78\tLoss: 0.4990\t MAE: 0.5209\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  90\n",
      "  0 sec | Step  78\tLoss: 0.4990\t MAE: 0.5209\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  91\n",
      "  0 sec | Step  78\tLoss: 0.4989\t MAE: 0.5208\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  92\n",
      "  0 sec | Step  78\tLoss: 0.4989\t MAE: 0.5208\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  93\n",
      "  0 sec | Step  78\tLoss: 0.4988\t MAE: 0.5207\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  94\n",
      "  0 sec | Step  78\tLoss: 0.4989\t MAE: 0.5207\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  95\n",
      "  0 sec | Step  78\tLoss: 0.4987\t MAE: 0.5207\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  96\n",
      "  0 sec | Step  78\tLoss: 0.4989\t MAE: 0.5208\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  97\n",
      "  0 sec | Step  78\tLoss: 0.4988\t MAE: 0.5207\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  98\n",
      "  0 sec | Step  78\tLoss: 0.4989\t MAE: 0.5208\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch  99\n",
      "  0 sec | Step  78\tLoss: 0.4987\t MAE: 0.5207\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n",
      "Epoch 100\n",
      "  0 sec | Step  78\tLoss: 0.4988\t MAE: 0.5207\n",
      "  0 sec | Step  19\tLoss: 0.8060\t MAE: 0.6920\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "train_mean_losses = []\n",
    "valid_mean_losses = []\n",
    "train_maes = []\n",
    "valid_maes = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_mae.reset_states()\n",
    "    validation_mae.reset_states()\n",
    "    mean_train_loss = 0.0\n",
    "    mean_valid_loss = 0.0\n",
    "    start = time.time()\n",
    "    learning_rate = scheduler(epoch)\n",
    "    optimizer.learning_rate = learning_rate\n",
    "    print(f'Epoch {epoch + 1:>3}')\n",
    "\n",
    "    for step, (movie, user, y_true) in enumerate(train_ds):\n",
    "        loss = training_step(movie, user, y_true)\n",
    "        \n",
    "        mae = train_mae.result()\n",
    "        mean_train_loss = mean_train_loss + (1 / (step + 1)) * (loss - mean_train_loss)\n",
    "        end = time.time()\n",
    "        print(f'\\r{int(end - start):>3} sec | Step {step:>3}\\tLoss: {mean_train_loss:>2.4f}\\t MAE: {mae:>2.4f}', end='')\n",
    "    print()\n",
    "    train_mean_losses.append(mean_train_loss)\n",
    "    train_maes.append(mae)\n",
    "\n",
    "    for step, (movie, user, y_true) in enumerate(test_ds):\n",
    "        loss = validation_step(movie, user, y_true)\n",
    "\n",
    "        mae = validation_mae.result()\n",
    "        mean_valid_loss = mean_valid_loss + (1 / (step + 1)) * (loss - mean_valid_loss)\n",
    "        end = time.time()\n",
    "        print(f'\\r{int(end - start):>3} sec | Step {step:>3}\\tLoss: {mean_valid_loss:>2.4f}\\t MAE: {mae:>2.4f}', end='')\n",
    "    print()\n",
    "    valid_mean_losses.append(mean_valid_loss)\n",
    "    valid_maes.append(mae)\n",
    "\n",
    "history = {'loss':train_mean_losses, 'val_loss':valid_mean_losses, 'mae':train_maes, 'val_mae':valid_maes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ee758-c3a0-4b2b-ade1-be62c1390d3b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1e240438-bcf9-40a8-a452-9ddb73c66748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneath the Planet of the Apes (1970)\n",
      "4.4919667\n",
      "\n",
      "The Raid 2: Berandal (2014)\n",
      "4.4866266\n",
      "\n",
      "Third Man, The (1949)\n",
      "4.482878\n",
      "\n",
      "Conan the Destroyer (1984)\n",
      "4.373156\n",
      "\n",
      "Nine to Five (a.k.a. 9 to 5) (1980)\n",
      "4.349896\n",
      "\n",
      "Matrix, The (1999)\n",
      "4.3490014\n",
      "\n",
      "Braveheart (1995)\n",
      "4.3328705\n",
      "\n",
      "The Imitation Game (2014)\n",
      "4.3306036\n",
      "\n",
      "Angels in the Outfield (1994)\n",
      "4.3225784\n",
      "\n",
      "Big Top Pee-Wee (1988)\n",
      "4.303034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_movies = np.unique(movies)\n",
    "test_users = (np.ones(unique_movies.shape[0]) * 249).astype('float32')\n",
    "test_movies = unique_movies.astype('float32')\n",
    "pred = model(test_movies, test_users, training=False)[:, 0]\n",
    "indx_pred = np.argsort(pred, axis=0)[::-1]\n",
    "\n",
    "for i in range(10):\n",
    "    print(titles.iloc[indx_pred[i]])\n",
    "    print(pred[indx_pred[i]].numpy() + mu)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0da48360-ae97-4334-80de-d3f5fe58d64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 4.1 and the true rating was 4.5\n",
      "Predicted 3.6 and the true rating was 2.5\n",
      "Predicted 3.6 and the true rating was 3.0\n",
      "Predicted 3.2 and the true rating was 1.0\n",
      "Predicted 3.3 and the true rating was 5.0\n",
      "Predicted 4.2 and the true rating was 3.0\n",
      "Predicted 3.2 and the true rating was 3.0\n",
      "Predicted 3.1 and the true rating was 3.0\n",
      "Predicted 3.2 and the true rating was 2.0\n",
      "Predicted 3.7 and the true rating was 1.5\n",
      "Predicted 3.7 and the true rating was 0.5\n",
      "Predicted 3.1 and the true rating was 5.0\n",
      "Predicted 3.5 and the true rating was 3.5\n",
      "Predicted 3.8 and the true rating was 4.5\n",
      "Predicted 3.4 and the true rating was 3.0\n",
      "Predicted 4.1 and the true rating was 2.5\n",
      "Predicted 3.8 and the true rating was 4.5\n",
      "Predicted 3.6 and the true rating was 4.0\n",
      "Predicted 3.2 and the true rating was 2.0\n",
      "Predicted 3.3 and the true rating was 4.0\n",
      "Predicted 3.7 and the true rating was 5.0\n",
      "Predicted 3.6 and the true rating was 4.0\n",
      "Predicted 3.4 and the true rating was 5.0\n",
      "Predicted 3.3 and the true rating was 4.0\n",
      "Predicted 3.8 and the true rating was 3.0\n",
      "Predicted 3.7 and the true rating was 4.0\n",
      "Predicted 3.3 and the true rating was 3.0\n",
      "Predicted 3.6 and the true rating was 4.5\n",
      "Predicted 4.1 and the true rating was 3.0\n",
      "Predicted 3.2 and the true rating was 3.0\n",
      "Predicted 3.6 and the true rating was 4.5\n",
      "Predicted 4.2 and the true rating was 4.5\n",
      "Predicted 3.7 and the true rating was 3.0\n",
      "Predicted 3.8 and the true rating was 1.5\n",
      "Predicted 3.2 and the true rating was 5.0\n",
      "Predicted 3.4 and the true rating was 5.0\n",
      "Predicted 3.5 and the true rating was 4.0\n",
      "Predicted 3.8 and the true rating was 4.0\n",
      "Predicted 3.0 and the true rating was 3.0\n",
      "Predicted 3.0 and the true rating was 3.0\n",
      "Predicted 3.1 and the true rating was 4.0\n",
      "Predicted 3.4 and the true rating was 4.0\n",
      "Predicted 3.0 and the true rating was 5.0\n",
      "Predicted 4.2 and the true rating was 5.0\n",
      "Predicted 3.3 and the true rating was 4.0\n",
      "Predicted 3.3 and the true rating was 1.5\n",
      "Predicted 4.3 and the true rating was 4.5\n",
      "Predicted 3.5 and the true rating was 4.0\n",
      "Predicted 3.7 and the true rating was 5.0\n",
      "Predicted 2.9 and the true rating was 5.0\n",
      "Predicted 3.6 and the true rating was 4.0\n",
      "Predicted 3.3 and the true rating was 5.0\n",
      "Predicted 3.8 and the true rating was 1.0\n",
      "Predicted 3.3 and the true rating was 5.0\n",
      "Predicted 3.8 and the true rating was 4.5\n",
      "Predicted 3.6 and the true rating was 4.0\n",
      "Predicted 3.2 and the true rating was 4.5\n",
      "Predicted 3.0 and the true rating was 3.0\n",
      "Predicted 3.0 and the true rating was 2.5\n",
      "Predicted 2.9 and the true rating was 4.0\n",
      "Predicted 3.4 and the true rating was 2.5\n",
      "Predicted 3.8 and the true rating was 3.5\n",
      "Predicted 3.7 and the true rating was 3.0\n",
      "Predicted 3.0 and the true rating was 3.0\n",
      "Predicted 3.5 and the true rating was 3.0\n",
      "Predicted 3.7 and the true rating was 3.0\n",
      "Predicted 3.9 and the true rating was 5.0\n",
      "Predicted 3.1 and the true rating was 2.0\n",
      "Predicted 3.3 and the true rating was 2.5\n",
      "Predicted 3.8 and the true rating was 4.0\n",
      "Predicted 3.3 and the true rating was 4.0\n",
      "Predicted 3.1 and the true rating was 4.0\n",
      "Predicted 3.7 and the true rating was 3.0\n",
      "Predicted 3.5 and the true rating was 3.0\n",
      "Predicted 3.8 and the true rating was 4.0\n",
      "Predicted 3.5 and the true rating was 3.0\n",
      "Predicted 3.7 and the true rating was 2.5\n",
      "Predicted 3.5 and the true rating was 2.0\n",
      "Predicted 3.4 and the true rating was 4.0\n",
      "Predicted 3.4 and the true rating was 5.0\n",
      "Predicted 3.4 and the true rating was 4.0\n",
      "Predicted 3.1 and the true rating was 2.5\n",
      "Predicted 3.3 and the true rating was 3.5\n",
      "Predicted 4.0 and the true rating was 4.0\n",
      "Predicted 3.2 and the true rating was 5.0\n",
      "Predicted 3.3 and the true rating was 4.0\n",
      "Predicted 3.9 and the true rating was 4.0\n",
      "Predicted 3.9 and the true rating was 3.0\n",
      "Predicted 3.2 and the true rating was 4.0\n",
      "Predicted 3.8 and the true rating was 3.0\n",
      "Predicted 3.3 and the true rating was 4.0\n",
      "Predicted 3.3 and the true rating was 3.0\n",
      "Predicted 3.6 and the true rating was 5.0\n",
      "Predicted 3.3 and the true rating was 2.0\n",
      "Predicted 3.7 and the true rating was 4.0\n",
      "Predicted 3.6 and the true rating was 4.0\n",
      "Predicted 3.7 and the true rating was 4.0\n",
      "Predicted 4.2 and the true rating was 1.0\n",
      "Predicted 4.1 and the true rating was 4.5\n",
      "Predicted 3.6 and the true rating was 0.5\n"
     ]
    }
   ],
   "source": [
    "max_loss = 0\n",
    "y_pred = model(test_movies, test_users, training=False)\n",
    "for i in range(100):\n",
    "    y_hat = y_pred[i].numpy()\n",
    "    y_true = test_ratings[i]\n",
    "    print(f'Predicted {y_hat[0] + mu:>2.2} and the true rating was {y_true + mu:>2.2}')\n",
    "    max_loss = max(max_loss, np.abs(y_hat - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d6908027-b22a-4bd1-a82e-dc6a3b1fa855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1654434], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "488817c1-ee90-4572-a5b6-61c3fad4619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.dense.Dense object at 0x78422ddcac90>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./models/collaborative_filtering_v1.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/collaborative_filtering_v1.tf/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/collaborative_filtering_v1.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1be037-d5cb-4e9c-ac55-57131fb25a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
